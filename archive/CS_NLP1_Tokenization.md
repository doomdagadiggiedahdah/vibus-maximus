# Text Tokenization

Breaking text into units for processing:
- Word tokenization splits by whitespace
- Subword tokenization handles unknown words
- Character tokenization provides finest granularity